% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utilities.R
\name{cv.supercent}
\alias{cv.supercent}
\title{SuperCENT k-fold cross-validation}
\usage{
cv.supercent(
  A,
  X,
  y,
  l = NULL,
  lrange = 2^4,
  gap = 2,
  folds = 10,
  tol = 1e-04,
  max_iter = 200,
  weights = rep(1, length(y)),
  verbose = 0,
  ...
)
}
\arguments{
\item{A}{The input network}

\item{X}{The design matrix}

\item{y}{The response vector}

\item{l}{The initial tuning parameter}

\item{lrange}{The search range of the tuning parameter}

\item{gap}{The search gap of the tuning parameter}

\item{folds}{The number of fold for cross-validation}

\item{tol}{The precision tolerance to stop}

\item{max_iter}{The maximum iteration}

\item{weights}{The weight vector for each observation in (X,y)}

\item{verbose}{Output detailed message at different levels}
}
\value{
Output a \code{cv.supercent} object
\describe{
  \item{d}{The estimated \eqn{d}}
  \item{u}{The estimated hub centrality}
  \item{v}{The estimated authority centrality}
  \item{beta}{The scaled estimated regression coeffcients}
  \item{l}{The tuning parameter \eqn{\lambda}}
  \item{residuals}{The residuals of the regression}
  \item{fitted.values}{The predicted response}
  \item{epsa}{The estimated \eqn{\sigma_a}}
  \item{epsy}{The estimated \eqn{\sigma_y}}
  \item{A}{The adjacency matrix of the input network}
  \item{X}{The input design matrix}
  \item{y}{The input response}
  \item{l_sequence}{The grid of the tuning parameter}
  \item{beta_cvs}{The estimated regression coefficients of \code{l_sequence}}
  \item{mse_cv}{The cross-validation MSEs of \code{l_sequence}}
  \item{cv_index}{The fold indices (X,y)}
  \item{iter}{The grid of the tuning parameter}
  \item{max_iter}{The maximum iteration}
  \item{u_distance}{The sequence of differences of \eqn{\hat{u}} between 
  the two consecutive iterations}
  \item{method}{The estimation method: supercent}
}
}
\description{
The SuperCENT methodology that simultaneously solves
the centrality estimation and regression using
k-fold cross-validation to choose the tuning parameter \eqn{\lambda}.
}
\examples{
n <- 100
p <- 3
sigmaa <- 1
sigmay <- 1e-5
A <- matrix(rnorm(n^2, sd = sigmaa), nrow = n)
X <- matrix(rnorm(n*p), nrow = n, ncol = p)
y <- rnorm(n, sd = sigmay)
ret <- cv.supercent(A, X, y)
}
